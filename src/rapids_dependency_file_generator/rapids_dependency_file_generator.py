import itertools
import os
import textwrap
from collections import defaultdict

import yaml

from .constants import (
    OutputTypes,
    cli_name,
    default_channels,
    default_conda_dir,
    default_requirements_dir,
)

OUTPUT_ENUM_VALUES = [str(x) for x in OutputTypes]
NON_NONE_OUTPUT_ENUM_VALUES = [str(x) for x in OutputTypes if not x == OutputTypes.NONE]


def dedupe(dependencies):
    deduped = sorted({dep for dep in dependencies if not isinstance(dep, dict)})
    dict_deps = defaultdict(list)
    for dep in filter(lambda dep: isinstance(dep, dict), dependencies):
        for key, values in dep.items():
            dict_deps[key].extend(values)
            dict_deps[key] = sorted(set(dict_deps[key]))
    if dict_deps:
        deduped.append(dict(dict_deps))
    return deduped


def grid(gridspec):
    """Yields the Cartesian product of a `dict` of iterables.

    The input ``gridspec`` is a dictionary whose keys correspond to
    parameter names. Each key is associated with an iterable of the
    values that parameter could take on. The result is a sequence of
    dictionaries where each dictionary has one of the unique combinations
    of the parameter values.
    """
    for values in itertools.product(*gridspec.values()):
        yield dict(zip(gridspec.keys(), values))


def make_dependency_file(
    file_type, name, config_file, output_path, conda_channels, dependencies
):
    relative_path_to_config_file = os.path.relpath(config_file, output_path)
    file_contents = textwrap.dedent(
        f"""\
        # This file is generated by `{cli_name}`.
        # To make changes, edit {relative_path_to_config_file} and run `{cli_name}`.
        """
    )
    if file_type == str(OutputTypes.CONDA):
        file_contents += yaml.dump(
            {
                "name": os.path.splitext(name)[0],
                "channels": conda_channels,
                "dependencies": dependencies,
            }
        )
    if file_type == str(OutputTypes.REQUIREMENTS):
        file_contents += "\n".join(dependencies) + "\n"
    return file_contents


def validate_requested_output_types(output):
    output = output if isinstance(output, list) else [output]

    if output == [str(OutputTypes.NONE)]:
        return []

    if len(output) > 1 and str(OutputTypes.NONE) in output:
        raise ValueError("'output: [none]' cannot be combined with any other values.")

    if any(v not in NON_NONE_OUTPUT_ENUM_VALUES for v in output):
        raise ValueError(
            "'output' key can only be "
            + ", ".join(f"'{x}'" for x in OUTPUT_ENUM_VALUES)
            + f" or a list of the non-'{OutputTypes.NONE}' values."
        )
    return output


def get_filename(file_type, file_prefix, matrix_combo):
    file_type_prefix = ""
    file_ext = ""
    if file_type == str(OutputTypes.CONDA):
        file_ext = ".yaml"
    if file_type == str(OutputTypes.REQUIREMENTS):
        file_ext = ".txt"
        file_type_prefix = "requirements"
    suffix = "_".join([f"{k}-{v}" for k, v in matrix_combo.items()])
    filename = "_".join(
        x for x in [file_type_prefix, file_prefix, suffix] if x
    ).replace(".", "")
    return filename + file_ext


def get_output_path(file_type, config_file_path, file_config):
    output_path = "."
    if file_type == str(OutputTypes.CONDA):
        output_path = file_config.get("conda_dir", default_conda_dir)
    if file_type == str(OutputTypes.REQUIREMENTS):
        output_path = file_config.get("requirements_dir", default_requirements_dir)
    return os.path.join(os.path.dirname(config_file_path), output_path)


def should_use_specific_entry(matrix_combo, specific_entry_matrix):
    # TODO: Is the branch even reachable?
    if not specific_entry_matrix:
        return True

    for specific_key, specific_value in specific_entry_matrix.items():
        if matrix_combo.get(specific_key) != specific_value:
            return False
    return True


def make_dependency_files(parsed_config, config_file_path, to_stdout):

    channels = parsed_config.get("channels", default_channels) or default_channels
    files = parsed_config["files"]
    for file_name, file_config in files.items():
        includes = file_config["includes"]
        file_types_to_generate = validate_requested_output_types(file_config["output"])

        for file_type in file_types_to_generate:
            for matrix_combo in grid(file_config.get("matrix", {})):
                dependencies = []

                for include in includes:
                    dependency_entry = parsed_config["dependencies"][include]

                    for common_entry in dependency_entry.get("common", []):
                        if file_type not in common_entry["output_types"]:
                            continue
                        dependencies.extend(common_entry["packages"])

                    for specific_entry in dependency_entry.get("specific", []):
                        if file_type not in specific_entry["output_types"]:
                            continue

                        for specific_matrices_entry in specific_entry["matrices"]:
                            if should_use_specific_entry(
                                matrix_combo, specific_matrices_entry["matrix"]
                            ):
                                dependencies.extend(
                                    # TODO: Can this actually be empty?
                                    specific_matrices_entry["packages"]
                                    or []
                                )
                                break
                        else:
                            raise ValueError(
                                f"No matching matrix found in '{include}' for: {matrix_combo}"
                            )

                # Dedupe deps and print / write to filesystem
                full_file_name = get_filename(file_type, file_name, matrix_combo)
                deduped_deps = dedupe(dependencies)

                output_path = (
                    "."
                    if to_stdout
                    else get_output_path(file_type, config_file_path, file_config)
                )
                contents = make_dependency_file(
                    file_type,
                    full_file_name,
                    config_file_path,
                    output_path,
                    channels,
                    deduped_deps,
                )

                if to_stdout:
                    print(contents)
                else:
                    os.makedirs(output_path, exist_ok=True)
                    with open(os.path.join(output_path, full_file_name), "w") as f:
                        f.write(contents)
